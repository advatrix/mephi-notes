**Опр.** Оптимизация -- достижение наилучшего качества при ограничении на ресурсы.

Качество задаётся в виде формулы $f = f(x_1, \ldots, x_n)$ и зависит от $x_1\ldots x_n$.

Рассмотрим достижение максимума/минимума функции $f$ в случаях:
- $-\infty < x_i < \infty$ (ресурсы не ограничены). Используются экстремумы функций многих переменных
- $\leq x_1\ldots x_n\leq$ (ограничения и критерий задаются нелинейными функциями) -- метод нелинейного программирования. (про это есть учебник Химмельблау)
- $\leq x_1\ldots x_n\leq$ (ограничения и критерий задаются линейными функциями) -- $n$-мерный многогранник, высекаемый $n$-мерными плоскостями. Используется метод линейного программирования

ограничения:
- данные даются с какой-то точностью -- потеря точности при округлении
- потеря точности в ЭВМ
- потеря точности в методе

Число -- безразмерная величина. Понятия числа и величины есть синонимы. Одно и то же число в разных СС выглядит по-разному

СС -- система (математический приём) изображения чисел с помощью ограниченного количества символов

Мы работаем с позиционными СС. Это СС, в которой вклад цифр в величину числа зависит от положения цифры в числе относительно запятой

**Опр**. Пусть $A$ - точное значение числа, $a$ - то приближение, с которым мы будем работать. Тогда величина $\Delta = |A-a| = |a-A|$ называется **абсолютной погрешностью $a$**

**Опр**. $\delta = \frac{\Delta}{|A|}$ называется **относительной погрешностью приближенного числа $a$

Абсолютные и относительные погрешности работают в паре. **Они округляются только в большую сторону**. 

Например, $\Delta = 0.099 = 0.1$ 

Возможны два случая для расчета погрешностей:
- $A$ и $a$ известны (редкий случай). Тогда ранее приведенные формулы для погрешностей являются рабочими. Отсюда находим $\delta$
- $A$ неизвестно (наиболее часто). $a$ известно. Одним из известных способов находят $\Delta$ или $\delta$ и далее полагают, что $$\delta\simeq\frac\Delta a,$$потому что $A\simeq a$. Работая по этой формуле получаем, что $$a-\Delta\leq A\leq a+\Delta$$

Основные источники погрешностей:
- погрешность исходных данных. При обработке они переходят в результат.
- методическая погрешность. Например, значения интегралов можно считать по формулам прямоугольников, трапеций и каких-то умных челов.


## Десятичная запись приближенного числа. Значащие цифры и верные значащие цифры.

Всякое число $A$ может быть представлено в виде бесконечной дроби (**развернутая запись числа)**$$a=\alpha_1\cdot 10^{m-1} +\alpha_2\cdot 10^{m-2}+\ldots +\alpha_{m-1}10^1+\alpha_m10^0+\ldots+\alpha_n 10^{m-n}$$
В этой записи
- $\alpha_i$ -- десятичные цифры числа, $\alpha_i=\overline{0, 9}$
- $n$ -- разрядность числа 
- $m$ -- количество цифр в целой части числа

Например,
$$3141.59=3\cdot10^3+1\cdot10^2_4\cdot10^1+1\cdot10^0+5\cdot10^{-1}+9\cdot10^{-9}$$
Если ввести ограничение на то, что старший разряд не равен нулю:

$$b = \beta_1\cdot 10^{m-1}+\beta_2\cdot10^{m-2}+\ldots+ \beta_n\cdot 10^{m-n}\quad (\beta_1\neq 0)$$

**Опр**. Все сохраняемые десятичные цифры $\beta_i$ ($i = \overline{1, n}$) называются **значащими цифрами**. В числе 0.007010 цифры 7010 -- значащие.

**Опр**. Значащей цифрой приближённого числа называется всякая цифра в его записи, отличная от нуля; ноль, если он содержится между значащими цифрами или представляет сохраняемый десятичный разряд.

Примеры
- 10.89 - 4 зн цифры
- 0.007010 - 4 зн цифры
- 0.00701 - 3

Специальная математическая запись, показывающая количество значащих цифр:

$$689000 = 6.89 \cdot 10^5$$
- $6.89\cdot 10^5$ - 3 зн цифры
- $6.89000\cdot 10^5$ - 6 зн цифр
- $7\cdot 10^5$ - 1 зн цифра

0.000 000 120 
- с тремя зн цифрами $1.20 \cdot 10^{-7}$
- $1.2\cdot 10^{-7}$ с 2 зн цифрами


**Опр.** Говорят, что $n$ первых значащих цифр приближенного числа $a$ являются **верными**, если абсолютная погрешность этого числа не превышает половины единицы младшего $n$-го разряда.

Т. о. если для приближенного числа $a$ с $n$ разрядами, которое заменяет точное число $A$, известно, что 
$$\Delta=|A-a|\leq\frac12\cdot 10^{m-n},$$
то первые $n$ цифр этого числа $\alpha_1,\ldots,\alpha_n$ являются верными.

Например, если для 42.253 $\Delta = 0.004$
- берем младший разряд. проверяем 3 $\frac {10^{-3}}2=0.0005 < \Delta$ => не является верной зн цифрой
- дальше 5 $\frac{10^{-2}}2=0.005>\Delta$ => верно
подчеркнуть цифры и написать: подчеркнутые цифры являются верными

## Округление чисел

Рассмотрим некоторое число $a_{10}$ в десятичной СС. Иногда требуется записать его с меньшим количеством цифр $a\to a_1$ и выбрать $a_1$ так, чтобы погрешность перехода была наименьшей 

$$| a-a_1 | \to\min$$

это достигается соответствующими правилами округления:
- при округлении до $n$ значащих цифр отбрасываются все цифры, стоящие справа от $n$-ой значащей цифры, и если нужно сохранение разрядностей, заменяют их нулями. Два случая
	- если первая из отбрасываемых цифр меньше 5, то оставшиеся десятичные знаки остаются без изменения
	- если она $\geq 5$, то к последней оставляемой цифре добавляют единицу
- погрешность округления при этом не превышает 1/2 единицы последнего оставляемого десятичного разряда

пример
$\pi = 3.1415926535$
если округлить до 3.1416, то $\Delta\leq\frac12 \cdot 10^4$
- 3.142 $\Delta\leq\frac12 \cdot 10^-3$
- 3.14 $\Delta\leq\frac12 \cdot 10^{-2}$

точность приближенного числа зависит не от количества значащих цифр, а от количества **верных** значащих цифр.

## Практическое правило округления при вычислениях

в промежуточных результатах количество значащих цифр должно превосходить количество верных на одну-две цифры. Окончательный результат может содержать  не более, чем одну излишнюю значащую цифру. Это правило позволяет без ущерба для точности избегать написания лишних цифр.

## Общая формула для нахождения погрешностей

**основная задача теории погрешностей**: известны погрешности величин $x1\ldots x_n$, требуется найти погрешность заданной $f(x_1, \ldots, x_n)$ от этих величин

пусть задана дифференцируемая $f = f(x_1\ldots x_n)$ и известны $\Delta x_i$ - абсолютные погрешности агрументов. Тогда абсолютная погрешность функции 

$$\Delta f = |f(x_1 +\Delta x_1, \ldots, x_n + \Delta x_n) - f(x_1, \ldots, x_n)|$$
В силу малости $\Delta x_i$ можно записать так

$$\tag{1}\Delta f = \left| \sum_{i=1}^n\frac{\partial f}{\partial x_i}\Delta x_i\right|$$

$$\tag{2}\Delta f = \sum_{i=1}^n \left|\frac{\partial f}{\partial x_i}\right|\Delta x_i$$

(2) -- **общая формула для расчета погрешностей**

**обратная задача теории погрешностей**: каковы должны быть абсолютные погрешности агрументов функции, чтобы абсолютная погрешность функции не превышала заданной величины?

простейшее решение обратной задачи -- с использованием принципа равных влияний. согласно этому принципу предполагается, что все частные дифференциалы $\left |\frac {\partial f}{\partial x_i}\right |\Delta x_i$ вносят одинаковый вклад в абсолютную погрешность $\Delta f$ 

пусть $\Delta f$ задана, тогда 

$$\Delta f = \sum_{i=1}^n \left|\frac{\partial f}{\partial x_i}\right|\Delta x_i$$
$$\left|\frac{\partial f}{\partial x_1}\right|\Delta x_1=\left|\frac{\partial f}{\partial x_2}\right|\Delta x_2=\ldots=\left|\frac{\partial f}{\partial x_n}\right|\Delta x_n=\frac{\Delta f} f$$
$$\Delta x_i = \frac{\Delta f}{n\cdot \left|\frac{\partial f}{\partial x_i}\right|}$$

Формула (2) является приближенной, потому что там используются частные производные. Но если надо найти диапазон изменения функции в заданной точке, используется **метод границ** или и **метод двойных вычислений**, где, зная погрешности аргументов, можно точно указать диапазон изменения ф-ии

## Метод границ или метод двойных вычислений

Пусть $f(x_1, \ldots, x_n)$ непрерывна и монотонна по каждому аргументу. При этом сами аргументы находятся в диапазоне $x_{i_\min}\leq x_i\leq x_{i_\max}$

Тогда

$$ f(\underline x_1, \ldots, \underline x_n)\leq f\leq f(\overline x_1, \ldots, \overline x_n)$$

Слева - границы интервалов, где значения функции минимальны. Справа - границы интервалов, в которых функция максимальна. 

$$\Delta f_1 = \left|f(\overline x_1, \ldots, \overline x_n) - f(x_1, \ldots, x_n)\right|$$

$$\Delta f_2 = \left|f(x_1, \ldots, x_n) - f(\underline x_1, \ldots, \underline x_n)\right|$$
$$ f_0-\Delta f_2\leq f\leq f_0 + \Delta f_1$$
$$f = f_0\quad \begin{matrix}  + \Delta f_1; \quad \delta_1 = \frac{\Delta f_1}{f_0} \\ - \Delta f_2; \quad \delta_2 = \frac{\Delta f_2}{f_0}\end{matrix}$$

$$f = f_0\pm \Delta f;\quad \delta_1; \quad\text{if } \Delta f_1 = \Delta f_2$$

Здесь $f_0$ – значение функции в точке.

### Взаимосвязь относительных погрешностей приближенного числа с количеством верных цифр в записи числа 

Пусть дано $a = \alpha\cdot 10^{m-1}+\alpha_2\cdot 10^{m-2} + \ldots +\alpha_n \cdot 10^{m-n}\quad (\alpha_1\neq 0)$
Это число во всеми верными цифрами.

**Теорема**.. Если некоторое число $a$ имеет $n$ верных цифр, относительная погрешность этого числа $\delta$ не превышает величины

$$\delta\leq \frac 1{\alpha_1}\left(\frac 1{10}\right)^{n-1}$$

**Следствие 1**. За относительную погрешность числа $a$ можно принять величину, если в $a$ $n$ верных цифр.

$$\delta = \frac 1{\alpha_1}\left(\frac 1{10}\right)^{n-1}$$
**Следствие 2**. Если в записи числа 2 и больше верных цифр, то за относительную погрешность можно принять в 2 раза точнее

$$\delta = \frac 1{2\alpha_1}\left(\frac 1{10}\right)^{n-1}$$
В ДЗ можно аргументировать так: берём это приближение и эта величина должна быть ≤ заданного $\delta$, оттуда находим $n$.

### Полезная информация

| Количество верных цифр  |   Относительная погрешность  | Средняя величина    |
| --- | --- | --- |
|  1   | 5 - 50%    |   10%  |
|   2  |  0.5 - 5%   |  1%   |
|    3 | 0.05 - 0.5%    |  0.1%   |

## Правило определения верных значащих цифр в записи числа по абсолютной погрешности числа (по определению)

3 шага:
1. Берем 1, проверяем в разряде.
2. Делим её пополам
3. Сравниваем результат деления с абсолютной погрешностью. Если погрешности ≤ результату деления, то цифра в этом разряде является верной.

## Правило определения верных значащих цифр числа по заданной относительной погрешности

2 шага:
1. По формуле $\Delta = a\cdot \delta$ определяется величина абсолютной погрешности $\Delta$.
2. Применяется предыдущее правило для определения верных цифр числа по заданной абсолютной погрешности.

### Пример

результат = 25.4275 $\pm$ 0.0424

пишем с меньшим количеством цифр:
результат = 25.428 $\pm$ 0.043 (погрешность всегда округляется в большую сторону)

еще меньше цифр 
рез = 25.43 $\pm$ 0.05

---
$\Delta = 0.21$ округлить до одной значащей цифры → $\Delta = 0.3$

## Эмпирические формулы

Пусть выполнен эксперимент. Получен ряд значений $x_1\ldots x_n$ и $y_1\ldots y_n$.

Требуется найти эмпирическую формулу $y = f(x)$.

Построение этой формулы состоит из двух этапов.
1. Определение общего вида формулы (экспонента, степень, гипербола и тд)
2. Определение наилучших параметров формулы

Это **не задача интерполяции:** 
- Интерполяционный полином проходит точно по точкам, а эмпирическая формула – рядом с ними.
- эмпирическая формула, как правило, более проста
- она сглаживает местные погрешности; интерполяционный полином их, наоборот, собирает

### Замечание

При построении эмпирической формулы будем предполагать, что исходные данные эксперимента $x_i$ и $y_i$ положительны.

Но это не нарушает общность решения задачи:
- если $x_i < 0, y \geq 0$, мы можем уйти на работу с таблицей $(-x_i; y_i)$
- если наоборот, то работаем с $(x_i; -y_i)$
- если $x_i<0, y_i < 0$, то работаем с $(-x_i; y_i)$
- если они знакопеременны, то переходим к новым переменным
	- $\xi_i = m + x_i > 0$
	- $\eta_i = n + y_i > 0$ 
	- выбираем $m$ и $n$ в силу ограниченности таблицы
	- работаем с таблицей $(\xi_i, \eta_i)$

### Линейная зависимость

$$\begin{array}{c|c} x_i & x_1 & x_2 & x_3 & x_4 & \ldots \\\ y_i & y_1 & y_2 & y_3 & y_4 & \ldots\end{array}$$

Пусть мы считаем, что зависимость линейная (это наша гипотеза, и её надо проверить). Для этого эта таблица дополняется значениями 

$$\Delta x_i = x_{i+1} - x_i$$
$$\Delta y_i = y_{i+1} - y_i$$

$$\frac{\Delta x_i}{\Delta y_i}$$

Получаем

$$\begin{array}{c|c} x_i & x_1 & x_2 & x_3 & x_4 & \ldots \\\ y_i & y_1 & y_2 & y_3 & y_4 & \ldots\\\ \Delta x_i = x_{i+1} - x_i & \Delta x_1&\ldots\\\ \Delta y_i = y_{i+1} - y_i&\Delta y_1\\\ k_i = \frac{\Delta x_i}{\Delta y_i}&\frac{\Delta x_1}{\Delta y_2}\end{array}$$

Если оказывается, что $k_1\simeq k_2\simeq \ldots\simeq k_{n-1}$, то зависимость имеет линейный вид $y = kx + b$.

Если эксперимент выполнялся с постоянным шагом ($\Delta x_i = \text{const}$ ) то достаточно проверить $\Delta y_1 = \ldots = \Delta y_{n-1}$

### Степенная зависимость

Пусть гипотеза, такая, что $y = cx^a$, где
- $a, c$ – константы
- $c > 0$ (из предположения о том, что всё положительное)
- $x, y > 0$

логарифмируем:
$$y = cx^a$$

$$\lg y = a \lg x + \lg c$$

вводим новые переменные:

$$X = lg x\quad Y = \lg y$$
у новых переменных зависимость такая
$$Y = aX + b, \quad b = \lg c$$
мы пришли к тому, что чтобы исходная зависимость была степенная, надо, чтобы точки $N_i(\lg x_i, \lg y_i)$ лежали на одной прямой:

$$N = (\lg x_i, \lg y_i)$$

В соответствии с этим дополняем таблицу

$$\begin{array}{c|c} x_i & x_1 & x_2 & x_3 & x_4 & \ldots \\\ y_i & y_1 & y_2 & y_3 & y_4 & \ldots\\\ X = \lg x&\lg x_1\\\ Y = \lg y&\lg y_1\\\ \Delta X = \lg x_{i+1} - \lg x_i&\lg x_2 - \lg x_1\\\ \Delta Y = \lg y_{i+1} - \lg y_i \\\ \frac{\Delta Y}{\Delta X}\end{array}$$

Если $\frac{\Delta Y}{\Delta X}=\text{const}$, то исходная зависимость имеет вид $y = cx^a$.


### Показательная зависимость

Гипотеза: $y = ce^{ax}, \quad c>0$

Логарифмируем

$$\lg y = a_1 x + \lg c, \quad a_1 = a\lg e$$

вводим новые переменные

$$ X = x\quad Y = \lg y$$

в новых переменных зависимость принимает вид

$$ Y = a_1 X + b, \quad b = \lg c$$

чтобы исходная зависимость была показательная, нужно, чтобы точки $N_i(x_i, \lg y_i)$ лежали на одной прямой (это уже где-то было -_-)

дополняем таблицу

$$\begin{array}{c|c} x_i & x_1 & x_2 & x_3 & x_4 & \ldots \\\ y_i & y_1 & y_2 & y_3 & y_4 & \ldots\\\ Y = \lg y&\lg y_1\\\ \Delta X \\\ \Delta Y = \lg y_{i+1} - \lg y_i \\\ \frac{\Delta Y}{\Delta X}\end{array}$$

если $\frac {\Delta Y}{\Delta X} = \text{const}$, то это показательная зависимость

### Гиперболическая зависимость

гипотеза 

$$ y =\frac 1{ax + b}$$

$$ \frac 1y = ax + b$$

вводим новые переменные

$$ X = x\quad Y = \frac 1y$$

в них зависимость такая

$$ Y = aX + b$$

чтобы исходная зависимость была гиперболическая, нужно, чтобы точки $N_i(x_i, \frac 1{y_i})$ лежали на одной прямой

дополняем таблицу по аналогии с кейсами выше

$$\begin{array}{c|c} x_i & x_1 & x_2 & x_3 & x_4 & \ldots \\\ y_i & y_1 & y_2 & y_3 & y_4 & \ldots\\\ Y = \frac 1y&\frac 1{y_1}\\\ \Delta X \\\ \Delta Y \\\ \frac{\Delta Y}{\Delta X}\end{array}$$

если $\frac {\Delta Y}{\Delta X} \simeq \text{const}$, то это гиперболическая зависимость

### Квадратичная (параболическая) зависимость

гипотеза $y = ax^2 + bx + c\quad (a\neq 0)$

$$\tag 1 y = ax^2 + bx + c$$
- переносим эксперимент на плоскость (рисуем точки на графике)
- проводим плавную кривую $\Gamma$ вблизи экспериментальных точек и выбираем на этой кривой одну из точек $N(x_0, y_0)$, которая совпадает с некоторой экспериментальной точкой $M(x_k, y_k)$
- координаты этой точки будут удовлетворять параболе
$$\tag 2 y_0 = ax_0^2 + bx_0 + c$$

- вычитаем (1) - (2)

$$y - y_0 = a(x^2 - x_0^2)+b(x-x_0)$$
- дополняем до полного квадрата при $a$

$$y - y_0 = a(x - x_0)^2 + b_1(x - x_0), \quad b_1 = b + 2ax_0$$

- вводим новые переменные

$$X = x - x_0\quad Y = \frac{y - y_0}{x - x_0}$$

- тогда получаем зависимость

$$ Y = aX + b_1$$

если точки $N_i = (X_i, Y_i), X_i = x_i - x_0; Y_i = \frac{y_i - y_0}{x_i - x_0}$ лежат на одной прямой, то исходные точки лежат на параболе


## Определение параметров эмпирической формулы

если выбран общий вид формулы $y = \overline f(x; a_1, \ldots, a_m)$, то следующим шагом является нахождение наилучших параметров $a_i$

есть три метода для этого
- метод выбранных точек
- метод средних
- метод наименьших квадратов

В БДЗ можно пользоваться любым методом

**Формулировка задачи**. Пусть дана система значений $M_i(x_i, y_i)$ – эксперимент (n точек). Она приближенно описывается формулой вида $y = \tilde f (x, a_1, \ldots, a_m)$, где $\tilde f$ – это известная функция, $a_i$ – некоторые постоянные (параметры) (m < n).

Нас интересуют величины параметров.

У нас имеются экспериментальные точки 

$$
\begin{cases}y_i = \tilde f(x_i, a_1, \ldots, a_m) + \varepsilon_i
\\\
i = 1, \ldots, n
\end{cases}
$$

$\varepsilon$ – это отклонения реальных точек от приближенного графика. Они называются **уклонения**.

У нас n уравнений, а неизвестных n + m. (эпсилоны и параметры).

Надо найти именно *наилучшие* параметры:

$$
y_i = f(x, \tilde a_1, \ldots, \tilde a_m) = \varepsilon_{i_\min}

$$

Геометрическая интерпретация: проведение графика функции так, чтобы он наиболее близко прилегал к экспериментальным точкам.

### Метод выбранных точек

Пусть для системы $M_i(x_i, y_i)$ из n точек построена общая формула $y = \tilde f (x, a_1, \ldots, a_m)$, m < n. $\tilde f$ известна.

Решение:

1. На координатную плоскость переносим точки эксперимента
2. На этой плоскости Oxy с наибольшей аккуратностью проводим кривую Г, чтобы она как можно ближе прилегала к этим точкам
3. На этой кривой выбираем систему из m точек по числу неизвестных параметров – $N_j(\tilde x_j, \tilde y_j), j=1\ldots m$.  Эти точки не обязательно должны совпадать с точками эксперимента

#### Требования к размещению точек $N_j$

1. Точки $N_j$ должны равномерно распределяться по всей рабочей части кривой Г.
2. Они должны как можно дальше отстоять друг от друга
3. Они не должны располагаться близко к малонадежным концевым точкам, то есть точкам $M_1$ и $M_n$

После этого со всей тщательностью замеряют координаты этих точек.

Тогда искомые параметры $a_1\ldots a_m$ могут быть определены из системы следующих уравнений

$$
\begin{cases}
\tilde y_j = \tilde f(\tilde x_j, a_1, \ldots, a_m)
\\\
j = 1, \ldots, m
\end{cases}
$$

То есть у нас m неизвестных и m уравнений.

#### Примеры применения метода для линейной зависимости

- $y = ax + b$
- надо найти параметры a, b
- переносим эксперимент на координатную плоскость
- строим кривую Г
- берем 2 точки $(\tilde x_1, \tilde y_1), (\tilde x_2, \tilde y_2)$ и записываем систему

$$
\begin{cases}
\tilde y_1 = a\tilde x_1 + b
\\\
\tilde y_2 = a\tilde x_2 +b
\end{cases}
$$

#### Примеры применения метода для квадратичной зависимости

- $y =ax^2 + bx + c$
- плоскость
- рисуем параболу Г
- три параметра => берем три точки, $(x_1, y_1), (x_2, y_2), (x_3, y_3)$


$$
\begin{cases}
\tilde y_1 = a\tilde x_1^2 + b\tilde x_1 + c
\\\
\tilde y_2 = a\tilde x_2^2 +b\tilde x_2 + c
\\\
\tilde y_3 = a\tilde x_3^2 +b\tilde x_3 + c
\end{cases}
$$

Это система из 3 линейных уравнений из 3 неизвестными, потому что иксы известны.

#### Преимущества и недостатки

Метод выбранных точек содержит геометрические построения, поэтому он является грубым. 

Достоинства: простота применения и наглядность.

К этому методу следует прибегать в тех случаях, когда точность исходных данных относительно невелика.

### Метод средних

Если в формулу $y = \tilde f(x, a_1, \ldots, a_m)$ подставить исходные данные $M_i(x_i, y_i)$, то в общем случае левая часть не будет равна правой

$$
\tilde f(x_i, a_1, \ldots, a_m) - y_i = \varepsilon_i
$$

Эпсилоны это расстояние по вертикали от функции до точек.

Суть метода: наилучшее расположение эмпирической кривой это когда $\displaystyle \sum_{i=1}^n \varepsilon_i = 0$.

1. Записывается система из n уравнений (по числу эмпирических точек)

$$
\begin{cases}
\tilde f(x_i, a_1, \ldots, a_m) - y_i = \varepsilon_i
\\\
i = 1, \ldots, n
\end{cases}
$$

2. Уравнения разбиваются на m групп (по числу неизвестных параметров)
3. Уравнения суммируются в группах
4. Решается система из m уравнений с m неизвестными $a_1, \ldots, a_m$. Причем суммы уравнений в группах приравниваются к нулю.


#### Пример применения метода средних

экспериментальные точки


| t   | 7    | 12   | 17   | 22   | 27   | 32   | 37   |
| --- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| Q   | 83.7 | 72.9 | 63.2 | 54.7 | 47.5 | 41.4 | 36.3 |



это парабола, гипотеза $Q = at^2 + bt + c$


Составляем 7 уравнений (по 7 точкам) и разбиваем на 3 группы

$$
\begin{array}{}
\begin{cases}
\varepsilon_1 = 49a + 7b + c - 83.7
\\\
\varepsilon_2 = 144a + 12b + c - 72.9
\\\
\varepsilon_3 = 289a + 17b + c - 63.2
\end{cases}
\\\
\begin{cases}
\varepsilon_4 = 484a + 22b + c - 54.7
\\\
\varepsilon_5 = 729a + 27b + c - 47.5
\end{cases}
\\\
\begin{cases}
\varepsilon_6 = 1024a + 32b + c - 41.4
\\\
\varepsilon_7 = 1369a + 37b + c - 36.3
\end{cases}
\end{array}
$$

Суммируем уравнения в группах

$$
\begin{cases}
482a + 36b + 3c - 219.8 = \varepsilon_1 + \varepsilon_2 + \varepsilon_3 = 0
\\\
1213a + 49 b + 2c - 102.2 = \varepsilon_4 + \varepsilon_5 = 0
\\\
2393a + 69 b + 2c - 77.7 = \varepsilon_6 + \varepsilon_7 = 0
\end{cases}
$$


Получается система из 3 уравнений. Решаем ее и получаем

$$
a = 0.0235, b = -2.6115, c = 100.8295
$$

Получаем такую эмпирическую формулу

$$
\tilde Q = 0.00235 t^2 - 2.6115 t + 100.8295
$$

Результаты метода средних **существенно** зависят от способа группировки отклонений. Практика показывает, что наиболее удачные эмпирические формулы получаются, если уклонения группируются в порядке последовательности их номеров, и каждая группа содержит, по возможности, одинаковое количество членов.

### Метод наименьших квадратов

Пусть известен вид эмпирической формулы  $y = \tilde f(x, a_1, \ldots, a_m)$ . Уклонения $\varepsilon_i = \tilde f(x_i, a_1, \ldots, a_m) - y_i$, $i = 1, \ldots n$/

Согласно МНК наилучшими величинами параметров $a_1, \ldots, a_m$ считаются те, для которых сумма квадратов отклонений минимальна

$$
\sum_{i=1}^n \varepsilon_i^2 =[\tilde f(x_i, a_1, \ldots, a_m) - y_i]^2 = S(a_1, \ldots, a_m)

$$

То есть это получается функция S от параметров. Далее, применяя необходимые условия экстремума функции многих переменных, получаем систему уравнений для определения параметров $a_j, j = 1, \ldots, m$.

$$
\begin{cases}
\frac{\partial S}{\partial a_1} = 0
\\\
\ldots
\\\
\frac{\partial S}{\partial a_m} = 0
\end{cases}
$$

Если система имеет единственное решение, то оно и будет искомым. 

МНК отличается тем преимуществом, что если сумма $S$ квадратов отклонений $\varepsilon_i$ мала, то сами эти уклонения также малы по абсолютной величине. Для метода средних, где оставляется алгебраическая сумма отклонений, такого вывода сделать нельзя (большие отклонения могут компенсировать друг друга).

Недостаток метода: сложность вычислений. К этому методу обычно прибегают при обработке наблюдений высокой точности.

# Интерполяция

Пусть для некоторой функции $y(x)$ известно, что при $x_0$ она принимает значение $y_0 = y(x_0)$ и так далее

Нам известны n эмпирических значений $y_i = y(x_i)$. Строить эмпирическую формулу мы не хотим, но хотим с этой функцией работать. Тогда прибегают к интерполяции: исходную функцию приближенно заменяется другой функцией $y(x)\simeq P(x)$, которую называют **интерполяционным полиномом**, такую, что

$$
P(x_0) = y_0\quad\ldots\quad P(x_n) = y_n
$$

то есть этот полином вьётся через экспериментальные точки. 

При этом $x\in [x_0, x_n]$.

**Замечание**. Если мы работаем с $x < x_0; x > x_n$ – то есть построили интерполяционный полином, но стали работать за его краями, то замена функции будет называться **экстраполяцией**

**Замечание**. Интерполяция и экстраполяция – частные случаи **аппроксимации**.

Для записи интерполяционных многочленов существует достаточно большое количество формул. Например, известны интерполяционные формулы Лагранжа, Ньютона, Гаусса, Бесселя, Стирлинга, Грегори-Ньютона, Лапласа-Эверетта и другие.  

Мы рассмотрим первые две формулы. Формулу Лагранжа трудно забыть ~~и легко потерять~~, а формула Ньютона наиболее удобна для расчетов вручную и на ЭВМ.

## Интерполяционная формула Лагранжа

Пусть имеются значения аргумента $x_0, \ldots, x_n$. – всего n+1 значение с некоторым шагом и значения $y_0 \ldots y_n$. Тогда интерполяционная формула Лагранжа имеет следующий вид

$$
P_n(x)_{\text{Лагр}} = 
\begin{array}{}
\frac{(x-x_1)(x-x_2)\dots (x-x_n)}{(x_0-x_1)(x_0-x_2)\dots (x_0-x_n)} y_0&+& x = x_0; P(x_0 ) = y_0
\\\
\frac{(x-x_0)(x-x_2)\dots (x-x_n)}{(x_1-x_0)(x_1-x_2)\dots (x_1-x_n)}y_1 &+ & x = x_1; P(x_1 ) = y_1
\\\
\ldots
\\\
\frac{(x-x_0)(x-x_1)\dots (x-x_{n-1})}{(x_n-x_0)(x_n-x_1)\dots (x_n-x_{n-1})}y_n & & x = x_n; P(x_n ) = y_n
\end{array}
$$

## Формула Ньютона

БДЗ будем делать по этой формуле. Будут даны точки, и будем считать интерполяцию в двух точках вперед и назад.

Наиболее удобной для вычислений на ЭВМ и вручную является формула Ньютона. Имеется n+1 точка $(x_i, y_i)$, и шаг переменный.

При переменном шаге применяются разделенные разности. Они определяются при помощи следующих соотношений.

- Разделенная разность первого порядка – это число $y(x_0, x_1) = [y(x_1) - y(x_0)] / (x_1 - x_0)$
- Разделенная разность второго порядка – это число $y(x_0, x_1, x_2) = [y(x_1, x_2) - y(x_0, x_1)] / (x_2 - x_0)$. То есть используются разделенные разности первого порядка и делятся на длину всего отрезка
- Разделенная разность третьего порядка $y(x_0, x_1, x_2, x_3) = [y(x_1, x_2, x_3) - y(x_0, x_1, x_2)] / (x_3 - x_0)$
- и так далее

Разделенные разности первого, второго и более высоких порядков имеют размерности производных соответствующих порядков. Они дают приближенные значения этих производных в соответствующих точках. Мы записали эти значения для точки $x_0$.

На отрезке $[x_0, x_n]$ интерполяционная формула Ньютона имеет следующий вид

$$
y(x) \simeq P_n(x)_{\text{Ньют}} = y(x_0)+(x-x_0)y(x_0, x_1)+(x-x_0)(x-x_1)y(x_0, x_1, x_2)+\ldots +(x-x_0)(x-x_1)\cdots (x-x_{n-1})y(x_0, x_1, \ldots, x_n)
$$

$$
= y(x_0)+\sum_{k=1}^n(x-x_0)(x-x_1)\cdots (x-x_{k-1})\cdot y(x_0, x_1, \ldots, x_k)
$$

### Таблица разделенных разностей табулированной функции $y = f(x)$ для проведения вычислений


| x0  | y(x0) | y(x0, x1)  = (y(x0)-y(x1))(x1-x0) |                                             |                                                       |
| --- | ----- | --------------------------------- | ------------------------------------------- | ----------------------------------------------------- |
| x1  | y(x1) | y(x1, x2)                         | y(x0, x1, x2) = (y(x1,x2)-y(x0,x1))/(x2-x0) | y(x0, x1, x2, x3) = (y(x1,x2,x3)-y(x0,x1,x2))/(x3-x0) |
| x2  | y(x2) | y(x2, x3)                         | y(x1, x2, x3)                               |                                                       |
| x3  | y(x3) |                                   |                                             |                                                       |

За точностью расчетов при применении формулы Ньютона удобно следить визуально: оценивают скорость убывания составляющих суммы, оставляют те составляющие, которые больше допустимой погрешности (абсолютной).

### Пример

Пусть дана функция синуса в первом квадранте $y(x) = \sin (30 \degree \cdot x), 0\leq x \leq 3$. Вычислить функцию при $x =1.5$, применяя 4 известных значения.

$y(1.5) = \sin(30\degree \cdot x)=\frac{\sqrt2}2$

Составляем таблицу

| xi  | y(xi)  | y(xi, xi-1) |               y(xi, xi+1, xi+2)                              |              y(xi, xi+1, xi+2, xi+3)                                         |
| --- | ------ | --------------------------------- | ------------------------------------------- | ----------------------------------------------------- |
| 0   | 0.0000 |                        0.500           |                                             |                                                       |
| 1    |     0.5000   |                      0.366             |      -0.067                                       |           -0.016                                            |
|  2   |     0.8666   |                           0.134        |            -0.116                                 |                                                       |
|   3  |   1.000     |                                   |                                             |                                                       |

$$
y(x) = y(x_0)+(x-x_0)y(x_0, x_1)+(x-x_0)(x-x_1)y(x_0, x_1, x_2)+(x-x_0)(x-x_1)(x-x_2)y(x_0, x_1, x_2, x_3)

$$

$$
y(1.5) = 0+1.5\cdot 0.500+1.5\cdot 0.5\cdot (-0.067)+1.5\cdot0.5\cdot(-0.5)\cdot(-0.016)=0+0.0750-0.050+0.006=0.706
$$

(Точное значение 0.707)